{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Mask Detector Video Stream.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"oe2SrUegZj-V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595278751581,"user_tz":-60,"elapsed":2112,"user":{"displayName":"Arunkumar Sudhakaran Nair","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqJ6q8d7glvRkiDr5mbbtbGOURBbf5ouFSz_Dv1g=s64","userId":"14214072824719308472"}},"outputId":"9356c495-6e74-443e-9cc4-444868df97b5"},"source":["from keras.preprocessing.image import img_to_array\n","import imutils\n","import cv2\n","from keras.models import load_model\n","import numpy as np"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mTXJe-P0Zj-e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595278751583,"user_tz":-60,"elapsed":2107,"user":{"displayName":"Arunkumar Sudhakaran Nair","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqJ6q8d7glvRkiDr5mbbtbGOURBbf5ouFSz_Dv1g=s64","userId":"14214072824719308472"}},"outputId":"6267035e-9869-4203-998f-b60f7e79301b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","detection_model_path= '/content/drive/My Drive/Code/haarcascade_frontalcatface.xml'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cRzOWUScZj-j","colab_type":"code","colab":{}},"source":["emotion_model_path = '/content/drive/My Drive/Code/mask_trained_model.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2n_JwRT8Zj-n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595278751585,"user_tz":-60,"elapsed":2096,"user":{"displayName":"Arunkumar Sudhakaran Nair","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqJ6q8d7glvRkiDr5mbbtbGOURBbf5ouFSz_Dv1g=s64","userId":"14214072824719308472"}},"outputId":"c74fed15-4bc2-414f-e1ca-0ce80ff090ba"},"source":["detection_model_path"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/content/drive/My Drive/Code/haarcascade_frontalcatface.xml'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"i2rBceLmZj-s","colab_type":"code","colab":{}},"source":["# hyper-parameters for bounding boxes shape\n","# loading models\n","face_detection = cv2.CascadeClassifier(detection_model_path)\n","emotion_classifier = load_model(emotion_model_path, compile=False)\n","EMOTIONS = [\"no mask\",\"mask\",]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWcOiq6cZj-x","colab_type":"code","colab":{}},"source":["# starting video streaming\n","cv2.namedWindow('your_face')\n","camera = cv2.VideoCapture(0)\n","while True:\n","    frame = camera.read()[1]\n","    #reading the frame\n","    frame = imutils.resize(frame,width=600)\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n","\n","    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n","    frameClone = frame.copy()\n","    if len(faces) > 0:\n","        faces = sorted(faces, reverse=True,\n","        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n","        (fX, fY, fW, fH) = faces\n","                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 48x48 pixels, and then prepare\n","            # the ROI for classification via the CNN\n","        roi_gray = gray[fY:fY + fH, fX:fX + fW]\n","        roi = frame[fY:fY + fH, fX:fX + fW]\n","        roi = cv2.resize(roi, (100, 100))\n","        roi = roi.astype(\"float\") / 255.0\n","        roi = img_to_array(roi)\n","        roi = np.expand_dims(roi, axis=0)\n","\n","\n","        preds = emotion_classifier.predict(roi)[0]\n","        emotion_probability = np.max(preds)\n","        label = EMOTIONS[preds.argmax()]\n","\n","\n","        for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n","                    # construct the label text\n","                    text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n","                    w = int(prob * 300)\n","                    cv2.rectangle(canvas, (7, (i * 35) + 5),\n","                    (w, (i * 35) + 35), (0, 0, 255), -1)\n","                    cv2.putText(canvas, text, (10, (i * 35) + 23),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n","                    (255, 255, 255), 2)\n","                    cv2.putText(frameClone, label, (fX, fY - 10),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n","                    cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n","                                  (0, 0, 255), 2)\n","\n","    cv2.imshow('your_face', frameClone)\n","    cv2.imshow(\"Probabilities\", canvas)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","camera.release()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]}]}